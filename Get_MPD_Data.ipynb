{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to where your Spotify Million Playlist is located.\n",
    "# The expected file structure is to have a data folder /data .csv files will be placed there.\n",
    "\n",
    "path = 'data/spotify_million_playlist_dataset/data'\n",
    "\n",
    "def loop_slices(path, num_slices=20):\n",
    "    \"\"\"\n",
    "    Each slice is a .json file containing 1000 playlists i.e.: 1 slice is 1000 playlists 20 slices is: 20,000 playlists.\n",
    "    Parameters:\n",
    "        num_slices (int): Number of slices to return, max 1000.\n",
    "        path (str): Path to the Spotify Million Playlist.\n",
    "        \n",
    "    Output:\n",
    "        mpd_playlists (list): a list of dictionaries of all the playlists.\n",
    "    \"\"\"\n",
    "    cnt=0\n",
    "    mpd_playlists = []\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        print(filename)\n",
    "        cnt+=1\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            current_slice = json.loads(js)\n",
    "            \n",
    "            # Create a list of all playlists\n",
    "            for playlist in current_slice['playlists']:\n",
    "                mpd_playlists.append(playlist)\n",
    "\n",
    "\n",
    "            if cnt == num_slices:\n",
    "                break\n",
    "    return mpd_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_csv(playlists, extended=False):\n",
    "    \"\"\"\n",
    "    This function will write a .csv file for all the input playlists, this .csv will have a single cell with all the tracks\n",
    "    in the playlist. \n",
    "    An extended parameter is available to extend the tracks in a list to be a single cell per song, this will return an \n",
    "    additional .csv file\n",
    "    Parameters:\n",
    "        playlists (list): a list of dictionaries such as that from the loop_slices() function.\n",
    "        extended (boolean): boolean to enable the extended .csv file generation\n",
    "        \n",
    "    Output:\n",
    "        MPD.csv: .csv file with the playlists\n",
    "        MPD.csv: .csv file with extended song columns\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(playlists)\n",
    "    df.to_csv('data/MPD.csv', index=False)\n",
    "    \n",
    "    if extended:\n",
    "        df_list = []\n",
    "        for playlist in playlists:\n",
    "            df_list.append(pd.DataFrame(playlist))\n",
    "            \n",
    "        df_extended = pd.concat(df_list, axis=0)\n",
    "         \n",
    "        cols_to_keep = ['name', 'collaborative', 'pid', 'modified_at', 'num_tracks', 'num_albums', \n",
    "                'num_followers','num_edits', 'duration_ms', 'num_artists']\n",
    "        df_extended = df_extended.reset_index().pivot(values='tracks',index=cols_to_keep, columns='index')\n",
    "        df_extended.reset_index(inplace=True)\n",
    "        df_extended = df_extended.rename_axis(None, axis=1)    \n",
    "        df_extended.sort_values('pid', inplace=True)\n",
    "        df_extended.to_csv('data/MPD_Extended.csv', index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#####################################################################################################################\n",
    "# STOP, STOP, STOP, STOP, STOP                                                                                      #\n",
    "# num_slices=1000 (all playlists) will take considerable time (>30min) and it will eat all your disk storage 30Gb+  #\n",
    "# recommended to work with default num_slices=20, this will output 400Mb for each file                              #\n",
    "#####################################################################################################################\n",
    "\n",
    "playlists = loop_slices(path, num_slices=20)\n",
    "create_csv(playlists, extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read MPD\n",
    "df = pd.read_csv('data/MPD.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MPD\n",
    "df = pd.read_csv('data/MPD_Extended.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
